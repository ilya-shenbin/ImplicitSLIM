{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T19:46:22.369126Z",
     "start_time": "2024-06-03T19:46:21.957290Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from downstream_models import MF, PLRec\n",
    "\n",
    "from utils import get_data, ndcg, recall\n",
    "\n",
    "from copy import deepcopy\n",
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T19:46:22.371987Z",
     "start_time": "2024-06-03T19:46:22.370328Z"
    }
   },
   "outputs": [],
   "source": [
    "seed = 1337\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T19:46:22.383553Z",
     "start_time": "2024-06-03T19:46:22.372736Z"
    }
   },
   "outputs": [],
   "source": [
    "dict_map = lambda d, f: {x: ((f(y[0]), f(y[1])) if isinstance(y, tuple) else f(y)) for x, y in d.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T19:46:23.428736Z",
     "start_time": "2024-06-03T19:46:22.384623Z"
    }
   },
   "outputs": [],
   "source": [
    "data = get_data('<specify your data directory here>')\n",
    "train_data, valid_in_data, valid_out_data, test_in_data, test_out_data = data\n",
    "n_users, n_items = train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T19:46:23.433616Z",
     "start_time": "2024-06-03T19:46:23.429725Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate(batch_size, device, data_in, data_out=None, shuffle=False, samples_perc_per_epoch=1):\n",
    "    assert 0 < samples_perc_per_epoch <= 1\n",
    "    \n",
    "    total_samples = data_in.shape[0]\n",
    "    samples_per_epoch = int(total_samples * samples_perc_per_epoch)\n",
    "    \n",
    "    if shuffle:\n",
    "        idxlist = np.arange(total_samples)\n",
    "        np.random.shuffle(idxlist)\n",
    "        idxlist = idxlist[:samples_per_epoch]\n",
    "    else:\n",
    "        idxlist = np.arange(samples_per_epoch)\n",
    "    \n",
    "    for st_idx in range(0, samples_per_epoch, batch_size):\n",
    "        end_idx = min(st_idx + batch_size, samples_per_epoch)\n",
    "        idx = idxlist[st_idx:end_idx]\n",
    "\n",
    "        yield Batch(device, idx, data_in, data_out)\n",
    "\n",
    "\n",
    "class Batch:\n",
    "    def __init__(self, device, idx, data_in, data_out=None):\n",
    "        self._device = device\n",
    "        self._idx = idx\n",
    "        self._data_in = data_in\n",
    "        self._data_out = data_out\n",
    "    \n",
    "    def get_idx(self):\n",
    "        return self._idx\n",
    "    \n",
    "    def get_idx_to_dev(self):\n",
    "        return torch.LongTensor(self.get_idx()).to(self._device)\n",
    "        \n",
    "    def get_ratings(self, is_out=False):\n",
    "        data = self._data_out if is_out else self._data_in\n",
    "        return data[self._idx]\n",
    "    \n",
    "    def get_ratings_to_dev(self, is_out=False):\n",
    "        return torch.Tensor(\n",
    "            self.get_ratings(is_out).toarray()\n",
    "        ).to(self._device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T19:46:23.453582Z",
     "start_time": "2024-06-03T19:46:23.434350Z"
    }
   },
   "outputs": [],
   "source": [
    "test_metrics = [{'metric': ndcg, 'k': 100}, {'metric': recall, 'k': 20}, {'metric': recall, 'k': 50}]\n",
    "\n",
    "def evaluate(model, data_in, data_out, metrics, model_kwargs, samples_perc_per_epoch=1, batch_size=2000):\n",
    "    metrics = deepcopy(metrics)\n",
    "    \n",
    "    for m in metrics:\n",
    "        m['score'] = []\n",
    "    \n",
    "    for batch in generate(batch_size=batch_size,\n",
    "                          device=None,\n",
    "                          data_in=data_in,\n",
    "                          data_out=data_out,\n",
    "                          samples_perc_per_epoch=samples_perc_per_epoch\n",
    "                         ):\n",
    "        \n",
    "        ratings_in = batch.get_ratings()\n",
    "        ratings_out = batch.get_ratings(is_out=True)\n",
    "    \n",
    "        ratings_pred = model.predict(ratings_in)\n",
    "        \n",
    "        if not (data_in is data_out):\n",
    "            ratings_pred[batch.get_ratings().nonzero()] = -np.inf\n",
    "            \n",
    "        for m in metrics:\n",
    "            m['score'].append(m['metric'](ratings_pred, ratings_out, k=m['k']))\n",
    "\n",
    "    for m in metrics:\n",
    "        m['score'] = np.concatenate(m['score']).mean()\n",
    "        \n",
    "    return [x['score'] for x in metrics]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T19:46:23.465984Z",
     "start_time": "2024-06-03T19:46:23.454236Z"
    }
   },
   "outputs": [],
   "source": [
    "best_score_ever = -np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T19:46:23.474117Z",
     "start_time": "2024-06-03T19:46:23.466721Z"
    }
   },
   "outputs": [],
   "source": [
    "def run(fixed_params, optimizing_params):\n",
    "    global best_score_ever\n",
    "    \n",
    "    optimizing_params = dict_map(optimizing_params, np.exp)\n",
    "    print(optimizing_params)\n",
    "    \n",
    "    params = fixed_params | optimizing_params\n",
    "\n",
    "    Model = params['model']\n",
    "    model = Model(train_data, params)\n",
    "\n",
    "    best_score = -np.inf\n",
    "    \n",
    "    # learning\n",
    "    \n",
    "    for epoch in range(-params['max_init_epochs'], params['max_train_epochs']):\n",
    "        \n",
    "        if epoch < 0:\n",
    "            model.init()\n",
    "            if params['max_train_epochs'] > 0:\n",
    "                continue\n",
    "        else:\n",
    "            if params['init_after_step']:\n",
    "                model.init()\n",
    "            model.step()\n",
    "\n",
    "        score = evaluate(model, valid_in_data, valid_out_data, [{'metric': ndcg, 'k': 100}], params, 1)[0]\n",
    "\n",
    "        print(score)\n",
    "\n",
    "        if score > best_score + 1e-4:\n",
    "            best_score = score\n",
    "            Q_best = model.Q.copy()\n",
    "            W_best = model.W.copy() if hasattr(model, 'W') else None\n",
    "        else:\n",
    "            break\n",
    "\n",
    "\n",
    "    # evaluaton\n",
    "    if best_score > best_score_ever:\n",
    "        best_score_ever = best_score\n",
    "        model.Q = Q_best\n",
    "        model.W = W_best\n",
    "        final_scores = evaluate(model, test_in_data, test_out_data, test_metrics, params)\n",
    "        for metric, score in zip(test_metrics, final_scores):\n",
    "            print(f\"{metric['metric'].__name__}@{metric['k']}:\\t{score:.4f}\")\n",
    "        for metric, score in zip(test_metrics, final_scores):\n",
    "            print(f\"{score:.3f}\")\n",
    "\n",
    "    \n",
    "    return best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T19:46:23.490235Z",
     "start_time": "2024-06-03T19:46:23.474820Z"
    }
   },
   "outputs": [],
   "source": [
    "# MF init + reg setup\n",
    "pbounds = {'item_λ': (1e1, 1e3), 'item_α': (1e-2, 1e1), 'item_thr': (1e0, 1e3),\n",
    "           'r_q':  (1e-1, 1e2), 's_q':  (1e-1, 1e3), 'r_p':  (1e-1, 1e3)\n",
    "          }\n",
    "probe_optimizing_params = {'item_thr': 264.76225833649335,\n",
    "                           'item_α': 0.8134979262528148,\n",
    "                           'item_λ': 944.9124867577675,\n",
    "                           'r_p': 1606.1732584049885,\n",
    "                           'r_q': 0.0002834483496119082,\n",
    "                           's_q': 26.91023013144844, \n",
    "                          }\n",
    "fixed_params = {'model': MF, \n",
    "                'L': 256, 'bias': True,\n",
    "                'max_init_epochs': 1, 'max_train_epochs': 10,\n",
    "                'init': 'ImplicitSLIM', 'reg': 'ImplicitSLIM',\n",
    "                'orth': False, 'init_after_step': False, \n",
    "               }\n",
    "\n",
    "# # PLRec + LLE-SLIM\n",
    "# pbounds = {'r_q':  (1e-3, 1e3), 'power':  (1, 10), 'item_λ': (1e2, 1e5)}\n",
    "# probe_optimizing_params = {'item_λ': 1218.249396070337, \n",
    "#                            'power': 2.8606363101792773, \n",
    "#                            'r_q': 19.64194050012942,\n",
    "#                           }\n",
    "# fixed_params = {'model': PLRec,\n",
    "#                 'L': 128, 'bias': False, \n",
    "#                 'max_init_epochs': 1, 'max_train_epochs': 1,\n",
    "#                 'init': 'LLE-SLIM', 'reg': 'none',\n",
    "#                 'orth': False, 'init_after_step': False, \n",
    "#                }\n",
    "\n",
    "# # PLRec\n",
    "# pbounds = {'r_q':  (1e-3, 1e3), 'power':  (1, 10)}\n",
    "# probe_optimizing_params = {'power': 1.2778018325012814, \n",
    "#                            'r_q': 0.008348500653807706,\n",
    "#                           }\n",
    "# fixed_params = {'model': PLRec,\n",
    "#                 'L': 256, 'bias': False, \n",
    "#                 'max_init_epochs': 1, 'max_train_epochs': 1,\n",
    "#                 'init': 'SVD', 'reg': 'none',\n",
    "#                 'orth': False, 'init_after_step': False, \n",
    "#                }\n",
    "\n",
    "# # MF\n",
    "# pbounds = {'r_p':  (1e-3, 1e3), 'r_q':  (1e-3, 1e3)}\n",
    "# probe_optimizing_params = {'r_p': 19.804162868530003,\n",
    "#                            'r_q': 185.54338507706711,\n",
    "#                           }\n",
    "# fixed_params = {'model': MF,\n",
    "#                 'L': 256, 'bias': True, \n",
    "#                 'max_init_epochs': 0, 'max_train_epochs': 20,\n",
    "#                 'init': 'none', 'reg': 'none',\n",
    "#                 'orth': False, 'init_after_step': False, \n",
    "#                }\n",
    "\n",
    "# # MF + LLE-SLIM\n",
    "# pbounds = {'r_p':  (1e-3, 1e3), 'power':  (1, 10), 'item_λ': (1e2, 1e5)}\n",
    "# probe_optimizing_params = {'item_λ': 4470.118449330024, \n",
    "#                            'power': 4.489624436421516, \n",
    "#                            'r_p': 0.15477826213462,\n",
    "#                           }\n",
    "# fixed_params = {'model': MF,\n",
    "#                 'L': 256, 'bias': True, \n",
    "#                 'max_init_epochs': 1, 'max_train_epochs': 0,\n",
    "#                 'init': 'LLE-SLIM', 'reg': 'none',\n",
    "#                 'orth': False, 'init_after_step': False, \n",
    "#                }\n",
    "\n",
    "# # MF multistep init setup\n",
    "# pbounds = {'item_λ': (1e1, 1e4), 'item_α': (1e-4, 1e1), 'item_thr': (1e0, 1e3),\n",
    "#            'r_p':  (1e-3, 1e3)\n",
    "#           }\n",
    "# probe_optimizing_params = {'item_thr': 394.82499101128354, \n",
    "#                            'item_α': 0.5176648566904536, \n",
    "#                            'item_λ': 597.4182355801788, \n",
    "#                            'r_p': 1414.4673175122664, \n",
    "#                           }\n",
    "# fixed_params = {'model': MF, \n",
    "#                 'L': 256, 'bias': True,\n",
    "#                 'max_init_epochs': 10, 'max_train_epochs': 0,\n",
    "#                 'init': 'ImplicitSLIM', 'reg': 'none',\n",
    "#                 'orth': False, 'init_after_step': False, \n",
    "#                }\n",
    "\n",
    "# # PLRec multistep init setup\n",
    "# pbounds = {'item_λ': (1e0, 1e4), 'item_α': (1e-3, 1e+1), 'item_thr': (1e0, 1e2),\n",
    "#            'r_q':  (1e-3, 1e3), 's_q':  (1e-3, 1e5), 'power':  (1, 1e5)\n",
    "#           }\n",
    "# probe_optimizing_params = {'item_thr': 82.39948654917328, \n",
    "#                            'item_α': 10.000000000000002, \n",
    "#                            'item_λ': 907.3171013771947, \n",
    "#                            'power': 10000.00000000001, \n",
    "#                            'r_q': 7.826179962320708, \n",
    "#                            's_q': 164074.31862023394, \n",
    "#                           }\n",
    "# fixed_params = {'model': PLRec, \n",
    "#                 'L': 256, 'bias': False,\n",
    "#                 'max_init_epochs': 0, 'max_train_epochs': 10,\n",
    "#                 'init': 'ImplicitSLIM', 'reg': 'ImplicitSLIM',\n",
    "#                 'orth': True, 'init_after_step': True, \n",
    "#                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T19:47:17.231634Z",
     "start_time": "2024-06-03T19:46:23.491549Z"
    }
   },
   "outputs": [],
   "source": [
    "run_wrapper = lambda **optimizing_params: run(fixed_params, optimizing_params)\n",
    "\n",
    "optimizer = BayesianOptimization(\n",
    "    f=run_wrapper,\n",
    "    pbounds=dict_map(pbounds, np.log),\n",
    "    verbose=2,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "optimizer.probe(\n",
    "    params=dict_map(probe_optimizing_params, np.log),\n",
    "    lazy=True,\n",
    ")\n",
    "\n",
    "optimizer.maximize(\n",
    "    init_points=0,\n",
    "    n_iter=0,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
